{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General packages\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Text Processing\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiments\n",
    "def get_sentiments(df):\n",
    "    df = vader_sentiment(df)\n",
    "    df = textblob_sentiment(df)\n",
    "    df['final_sentiment'] = df['Vader_compound_score'] + df['tb_polarity']\n",
    "\n",
    "    return df\n",
    "\n",
    "def vader_sentiment(df):\n",
    "    df['Vader_compound_score'] = df['Comment'].apply(lambda x: vader_compound_score(x))\n",
    "    return df\n",
    "\n",
    "def vader_compound_score(x):\n",
    "    vader_analyser = SentimentIntensityAnalyzer()\n",
    "    score = vader_analyser.polarity_scores(x)\n",
    "    return score['compound']\n",
    "\n",
    "def textblob_sentiment(df):\n",
    "    df['tb_polarity'] = df['Comment'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "    df['tb_subjectivity'] = df['Comment'].apply(lambda x: TextBlob(x).sentiment.subjectivity)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Travel Comments\n",
      "--------------------\n",
      "Before cleaning: 7058\n",
      "After cleaning: 6982\n"
     ]
    }
   ],
   "source": [
    "dominant_topics = pd.read_csv('../Data/travel_topics_topic_labels.csv')\n",
    "\n",
    "# remove rows containing empty comments\n",
    "print('Travel Comments')\n",
    "print('-'*20)\n",
    "print(f\"Before cleaning: {len(dominant_topics['Comment'])}\")\n",
    "dominant_topics.dropna(subset=['Comment'], inplace=True)\n",
    "print(f\"After cleaning: {len(dominant_topics['Comment'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get overview sentiments of comments for all topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_comments_sentiments_by_topic(topics_df, topic):\n",
    "    df = topics_df[topics_df[f'topic_{topic}'] == 1.0].reset_index()\n",
    "\n",
    "    df_sentiments = get_sentiments(df)\n",
    "\n",
    "    df_sentiments_pos = df_sentiments[df_sentiments['final_sentiment'] > 0]\n",
    "    df_sentiments_neu = df_sentiments[df_sentiments['final_sentiment'] == 0]\n",
    "    df_sentiments_neg = df_sentiments[df_sentiments['final_sentiment'] < 0]\n",
    "    \n",
    "    print(f\"There are {len(df_sentiments_pos)} positive comments regarding topic {topic}.\")\n",
    "    print(f\"There are {len(df_sentiments_neu)} neutral comments regarding topic {topic}.\")\n",
    "    print(f\"There are {len(df_sentiments_neg)} negative comments regarding topic {topic}.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1229 positive comments regarding topic 1.\n",
      "There are 231 neutral comments regarding topic 1.\n",
      "There are 607 negative comments regarding topic 1.\n",
      "\n",
      "There are 677 positive comments regarding topic 2.\n",
      "There are 71 neutral comments regarding topic 2.\n",
      "There are 413 negative comments regarding topic 2.\n",
      "\n",
      "There are 723 positive comments regarding topic 3.\n",
      "There are 50 neutral comments regarding topic 3.\n",
      "There are 413 negative comments regarding topic 3.\n",
      "\n",
      "There are 733 positive comments regarding topic 4.\n",
      "There are 86 neutral comments regarding topic 4.\n",
      "There are 488 negative comments regarding topic 4.\n",
      "\n",
      "There are 716 positive comments regarding topic 5.\n",
      "There are 80 neutral comments regarding topic 5.\n",
      "There are 426 negative comments regarding topic 5.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_num_comments_sentiments_by_topic(topics_df=dominant_topics, topic=1)\n",
    "get_num_comments_sentiments_by_topic(topics_df=dominant_topics, topic=2)\n",
    "get_num_comments_sentiments_by_topic(topics_df=dominant_topics, topic=3)\n",
    "get_num_comments_sentiments_by_topic(topics_df=dominant_topics, topic=4)\n",
    "get_num_comments_sentiments_by_topic(topics_df=dominant_topics, topic=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get top positive/neutral/negative comments under a topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corex_top_positive_comments(topics_df, topic, n):\n",
    "    df = topics_df[topics_df[f'topic_{topic}'] == 1.0].reset_index()\n",
    "\n",
    "    df_sentiments = get_sentiments(df)\n",
    "\n",
    "    df_sentiments_pos = df_sentiments[df_sentiments['final_sentiment'] > 0]\n",
    "    # df_sentiments_pos.to_csv('df_sentiments_pos_topic_2.csv')\n",
    "\n",
    "    print(f\"There are {len(df_sentiments_pos)} positive comments regarding topic {topic}. {round(len(df_sentiments_pos)/len(df_sentiments), 2) * 100} % of the comments are positive for this topic.\\n\\n\")\n",
    "    \n",
    "    positive_comments = df_sentiments_pos.sort_values(by='final_sentiment', ascending=False)['Comment'].to_list()\n",
    "\n",
    "    print_top_comments(positive_comments, n)\n",
    "\n",
    "def get_corex_neutral_comments(topics_df, topic, n):\n",
    "    df = topics_df[topics_df[f'topic_{topic}'] == 1.0].reset_index()\n",
    "\n",
    "    df_sentiments = get_sentiments(df)\n",
    "\n",
    "\n",
    "    df_sentiments_neu = df_sentiments[df_sentiments['final_sentiment'] == 0]\n",
    "    # df_sentiments_neu_2.to_csv('df_sentiments_neu_topic_2.csv')\n",
    "\n",
    "    print(f\"There are {len(df_sentiments_neu)} neutral comments regarding topic {topic}. {round(len(df_sentiments_neu)/len(df_sentiments), 2) * 100} % of the comments are neutral for this topic.\\n\\n\")\n",
    "    \n",
    "    comments = df_sentiments_neu['Comment'].sample(n=n).to_list()\n",
    "\n",
    "    print_comments(comments, n)\n",
    "\n",
    "def get_corex_top_negative_comments(topics_df, topic, n):\n",
    "    df = topics_df[topics_df[f'topic_{topic}'] == 1.0].reset_index()\n",
    "\n",
    "    df_sentiments = get_sentiments(df)\n",
    "\n",
    "    df_sentiments_neg = df_sentiments[df_sentiments['final_sentiment'] < 0]\n",
    "    print(f\"There are {len(df_sentiments_neg)} negative comments regarding topic {topic}. {round(len(df_sentiments_neg)/len(df_sentiments), 2) * 100} % of the comments are negative for this topic.\\n\\n\")\n",
    "    \n",
    "    # comments = df_sentiments_neg['Comment'].sample(n=n).to_list()\n",
    "    negative_comments = df_sentiments_neg.sort_values(by='final_sentiment', ascending=True)['Comment'].to_list()\n",
    "\n",
    "    print_top_comments(negative_comments, n)\n",
    "\n",
    "def print_top_comments(comments, n):\n",
    "    for i in range(n):\n",
    "        print(f'Rank {i+1} comment:')\n",
    "        print(f'{comments[i]}')\n",
    "        print()\n",
    "\n",
    "def print_comments(comments, n):\n",
    "    for i in range(n):\n",
    "        print(f'Comment {i+1}')\n",
    "        print(f'{comments[i]}')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Topic 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1229 positive comments regarding topic 1. 59.0 % of the comments are positive for this topic.\n",
      "\n",
      "\n",
      "Rank 1 comment:\n",
      "the best thing that has ever happened united states allows united states wfh\n",
      "\n",
      "Rank 2 comment:\n",
      "mohd countries like congo indonesia philippines and malaysia who are corrupted are invited they got best democracy even united states where got riots the capitol building and donald trump can talk abt democracy\n",
      "\n",
      "Rank 3 comment:\n",
      "eight continues can cme here spread but got chance spread sounds fair singapore ministers fucxxx fuxx off don talk please tell united states something make united states happy\n",
      "\n",
      "Rank 4 comment:\n",
      "mark zuckerbird like someone bought umbrella but they need united states buy one protect them from the rain lol\n",
      "\n",
      "Rank 5 comment:\n",
      "thailand please can not eat all the delicious and cheap thai foods and see all their beautiful women lol\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# positive comments for Topic 1\n",
    "get_corex_top_positive_comments(topics_df=dominant_topics, topic=1, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 607 negative comments regarding topic 1. 28.999999999999996 % of the comments are negative for this topic.\n",
      "\n",
      "\n",
      "Rank 1 comment:\n",
      "andylau google reporters without borders just deleted malaysia posts again one linked another explanation google contemptible and disgusting shitty paper\n",
      "\n",
      "Rank 2 comment:\n",
      "pap trying earn money and does not care about united states getting covid nineteen become sick die earning money out our misery and the corpse covid nineteen death absolutely inhumane\n",
      "\n",
      "Rank 3 comment:\n",
      "then why allow vaccinated travel lane into singapore all affected are coming singapore aggravate the situation disgusting\n",
      "\n",
      "Rank 4 comment:\n",
      "lin nothing with singapore how about germany then they are too having worst outbreak pandemic eversince vaccinated travel lane with singapore coincidence\n",
      "\n",
      "Rank 5 comment:\n",
      "schadenfreude that insulting singapore education system\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# negative comments for Topic 1\n",
    "get_corex_top_negative_comments(topics_df=dominant_topics, topic=1, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 231 neutral comments regarding topic 1. 11.0 % of the comments are neutral for this topic.\n",
      "\n",
      "\n",
      "Comment 1\n",
      "expect mass infection singapore following the dimwit strategy\n",
      "\n",
      "Comment 2\n",
      "why not india\n",
      "\n",
      "Comment 3\n",
      "singapore goes another circuit breaker then who will take responsibility this time\n",
      "\n",
      "Comment 4\n",
      "philippines are allowed travel singapore\n",
      "\n",
      "Comment 5\n",
      "germany just announced wave day\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# neutral comments for Topic 1\n",
    "get_corex_neutral_comments(topics_df=dominant_topics, topic=1, n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Topic 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 733 positive comments regarding topic 4. 56.00000000000001 % of the comments are positive for this topic.\n",
      "\n",
      "\n",
      "Rank 1 comment:\n",
      "avijeet well tell that the doctor who presented his work and lab studies the covid gop conference the guy has been working covid since sars unbiaised has one the best credentials with regards this virus\n",
      "\n",
      "Rank 2 comment:\n",
      "angmo boss very happy more rrt thought won hope contract covid lorry soon\n",
      "\n",
      "Rank 3 comment:\n",
      "slumps perfect one hundred ranking covid recovery index source nikkei asia five nov\n",
      "\n",
      "Rank 4 comment:\n",
      "peter mish agree with you covid nineteen taught united states the importance having plan good all believe all can relate this\n",
      "\n",
      "Rank 5 comment:\n",
      "love singapore but not take medicines and injections and stay home but know the maks not anything but will wear one keep from getting fined malaysia groceries were delivered malaysia home before the call pandemic moved queretaro mexico eleven two two thousand and where safe beautiful and clean like singapore\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# positive comments for Topic 4\n",
    "get_corex_top_positive_comments(topics_df=dominant_topics, topic=4, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 488 negative comments regarding topic 4. 37.0 % of the comments are negative for this topic.\n",
      "\n",
      "\n",
      "Rank 1 comment:\n",
      "andylau google reporters without borders just deleted malaysia posts again one linked another explanation google contemptible and disgusting shitty paper\n",
      "\n",
      "Rank 2 comment:\n",
      "pap trying earn money and does not care about united states getting covid nineteen become sick die earning money out our misery and the corpse covid nineteen death absolutely inhumane\n",
      "\n",
      "Rank 3 comment:\n",
      "hate covid hate covid hate covid hate covid hate covid\n",
      "\n",
      "Rank 4 comment:\n",
      "dislike comment section because has been infected with dangerous virus worst than covid\n",
      "\n",
      "Rank 5 comment:\n",
      "expect covid cases get worst\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# negative comments for Topic 4\n",
    "get_corex_top_negative_comments(topics_df=dominant_topics, topic=4, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 86 neutral comments regarding topic 4. 7.000000000000001 % of the comments are neutral for this topic.\n",
      "\n",
      "\n",
      "Comment 1\n",
      "but there are vaccinated people dying from covid\n",
      "\n",
      "Comment 2\n",
      "and now rebranded its creator covid pills\n",
      "\n",
      "Comment 3\n",
      "omicron coming\n",
      "\n",
      "Comment 4\n",
      "mohan sinnapillay covid nineteen only\n",
      "\n",
      "Comment 5\n",
      "its because theres still ample space hospitals for covid patients\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# neutral comments for Topic 4\n",
    "get_corex_neutral_comments(topics_df=dominant_topics, topic=4, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentiments = get_sentiments(dominant_topics)\n",
    "df_sentiments.to_csv('Output/travel_topics_sentiment_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label emotions for each comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_tokenize(data):    \n",
    "\n",
    "    #remove html markup\n",
    "    data = re.sub(\"(<.*?>)\", \"\", data)\n",
    "\n",
    "    #remove urls\n",
    "    data = re.sub(r'http\\S+', '', data)\n",
    "    \n",
    "    #remove hashtags and @names\n",
    "    data= re.sub(r\"(#[\\d\\w\\.]+)\", '', data)\n",
    "    data= re.sub(r\"(@[\\d\\w\\.]+)\", '', data)\n",
    "\n",
    "    #remove punctuation and non-ascii digits\n",
    "    data = re.sub(\"(\\\\W|\\\\d)\", \" \", data)\n",
    "    \n",
    "    #remove whitespace\n",
    "    data = data.strip()\n",
    "    \n",
    "    # tokenization with nltk\n",
    "    data = word_tokenize(data)\n",
    "    \n",
    "    # stemming with nltk\n",
    "    porter = PorterStemmer()\n",
    "    stem_data = [porter.stem(word) for word in data]\n",
    "        \n",
    "    return stem_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tl_ch\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.23.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\tl_ch\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.23.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\tl_ch\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator LinearSVC from version 0.23.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\tl_ch\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.23.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Comment</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>Vader_compound_score</th>\n",
       "      <th>tb_polarity</th>\n",
       "      <th>tb_subjectivity</th>\n",
       "      <th>final_sentiment</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>you have book the pcr test klia before arrival</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[fear]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>access good information what investors need pr...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8910</td>\n",
       "      <td>0.362500</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>1.253500</td>\n",
       "      <td>[neutral]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>please include philippines also are super stre...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7579</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.091233</td>\n",
       "      <td>[joy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>omicron mutated times thats making existing va...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.9168</td>\n",
       "      <td>-0.058788</td>\n",
       "      <td>0.499318</td>\n",
       "      <td>-0.975588</td>\n",
       "      <td>[fear]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>they are welcoming omicron into singapore when...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.3736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.373600</td>\n",
       "      <td>[anger]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            Comment  topic_1  \\\n",
       "0           0     you have book the pcr test klia before arrival      0.0   \n",
       "1           1  access good information what investors need pr...      0.0   \n",
       "2           2  please include philippines also are super stre...      0.0   \n",
       "3           3  omicron mutated times thats making existing va...      1.0   \n",
       "4           4  they are welcoming omicron into singapore when...      1.0   \n",
       "\n",
       "   topic_2  topic_3  topic_4  topic_5  Vader_compound_score  tb_polarity  \\\n",
       "0      0.0      0.0      0.0      0.0                0.0000     0.000000   \n",
       "1      0.0      0.0      0.0      0.0                0.8910     0.362500   \n",
       "2      0.0      1.0      0.0      0.0                0.7579     0.333333   \n",
       "3      0.0      1.0      1.0      0.0               -0.9168    -0.058788   \n",
       "4      0.0      0.0      1.0      1.0               -0.3736     0.000000   \n",
       "\n",
       "   tb_subjectivity  final_sentiment    Emotion  \n",
       "0         0.000000         0.000000     [fear]  \n",
       "1         0.425000         1.253500  [neutral]  \n",
       "2         0.666667         1.091233      [joy]  \n",
       "3         0.499318        -0.975588     [fear]  \n",
       "4         0.000000        -0.373600    [anger]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def emotions(df):\n",
    "    emotions_clf = pickle.load(open('../Data/tfidf_svm.sav', 'rb'))\n",
    "    df['Emotion'] = df['Comment'].apply(lambda x: emotions_clf.predict([x]))\n",
    "    return df\n",
    "\n",
    "df_emot = emotions(dominant_topics)\n",
    "df_emot.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emot.to_csv('Output/travel_topics_emotion_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get overview emotions of comments for all topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_comments_by_emotions_by_topic(topics_df, topic):\n",
    "    df = topics_df[topics_df[f'topic_{topic}'] == 1.0].reset_index()\n",
    "\n",
    "    comments_joy = df[df['Emotion'] == 'joy'].reset_index()\n",
    "    comments_sad = df[df['Emotion'] == 'sadness'].reset_index()\n",
    "    comments_anger = df[df['Emotion'] == 'anger'].reset_index()\n",
    "    comments_neu = df[df['Emotion'] == 'neutral'].reset_index()\n",
    "    comments_fear = df[df['Emotion'] == 'fear'].reset_index()\n",
    "\n",
    "    print(f\"There are {len(comments_joy)} joy comments regarding topic {topic}.\")\n",
    "    print(f\"There are {len(comments_sad)} sadness comments regarding topic {topic}.\")\n",
    "    print(f\"There are {len(comments_anger)} anger comments regarding topic {topic}.\")\n",
    "    print(f\"There are {len(comments_neu)} neutral comments regarding topic {topic}.\")\n",
    "    print(f\"There are {len(comments_fear)} fear comments regarding topic {topic}.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 230 joy comments regarding topic 1.\n",
      "There are 245 sadness comments regarding topic 1.\n",
      "There are 260 anger comments regarding topic 1.\n",
      "There are 946 neutral comments regarding topic 1.\n",
      "There are 386 fear comments regarding topic 1.\n",
      "\n",
      "There are 151 joy comments regarding topic 2.\n",
      "There are 162 sadness comments regarding topic 2.\n",
      "There are 206 anger comments regarding topic 2.\n",
      "There are 358 neutral comments regarding topic 2.\n",
      "There are 284 fear comments regarding topic 2.\n",
      "\n",
      "There are 165 joy comments regarding topic 3.\n",
      "There are 148 sadness comments regarding topic 3.\n",
      "There are 178 anger comments regarding topic 3.\n",
      "There are 464 neutral comments regarding topic 3.\n",
      "There are 231 fear comments regarding topic 3.\n",
      "\n",
      "There are 161 joy comments regarding topic 4.\n",
      "There are 174 sadness comments regarding topic 4.\n",
      "There are 219 anger comments regarding topic 4.\n",
      "There are 448 neutral comments regarding topic 4.\n",
      "There are 305 fear comments regarding topic 4.\n",
      "\n",
      "There are 143 joy comments regarding topic 5.\n",
      "There are 162 sadness comments regarding topic 5.\n",
      "There are 213 anger comments regarding topic 5.\n",
      "There are 466 neutral comments regarding topic 5.\n",
      "There are 238 fear comments regarding topic 5.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_num_comments_by_emotions_by_topic(topics_df=df_emot, topic=1)\n",
    "get_num_comments_by_emotions_by_topic(topics_df=df_emot, topic=2)\n",
    "get_num_comments_by_emotions_by_topic(topics_df=df_emot, topic=3)\n",
    "get_num_comments_by_emotions_by_topic(topics_df=df_emot, topic=4)\n",
    "get_num_comments_by_emotions_by_topic(topics_df=df_emot, topic=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get top comments by emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_comments_by_emotions(df, emotion, n):\n",
    "    df_sentiments = get_sentiments(df)\n",
    "\n",
    "    comments_emotion = df_sentiments[df_sentiments['Emotion'] == emotion].reset_index()\n",
    "\n",
    "    if emotion == 'joy':\n",
    "        comments = comments_emotion.sort_values(by='final_sentiment', ascending=False)['Comment'].to_list()\n",
    "    else:\n",
    "        comments = comments_emotion.sort_values(by='final_sentiment', ascending=True)['Comment'].to_list()\n",
    "    \n",
    "\n",
    "    print_top_comments(comments, n)\n",
    "\n",
    "def get_corex_top_comments_by_emotions(topics_df, topic, emotion, n):\n",
    "    df = topics_df[topics_df[f'topic_{topic}'] == 1.0].reset_index()\n",
    "    \n",
    "    df_sentiments = get_sentiments(df)\n",
    "\n",
    "    comments_emotion = df_sentiments[df_sentiments['Emotion'] == emotion].reset_index()\n",
    "\n",
    "    if emotion == 'joy':\n",
    "        comments = comments_emotion.sort_values(by='final_sentiment', ascending=False)['Comment'].to_list()\n",
    "    else:\n",
    "        comments = comments_emotion.sort_values(by='final_sentiment', ascending=True)['Comment'].to_list()\n",
    "    \n",
    "\n",
    "    print_top_comments(comments, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1 comment:\n",
      "avijeet well tell that the doctor who presented his work and lab studies the covid gop conference the guy has been working covid since sars unbiaised has one the best credentials with regards this virus\n",
      "\n",
      "Rank 2 comment:\n",
      "mohd countries like congo indonesia philippines and malaysia who are corrupted are invited they got best democracy even united states where got riots the capitol building and donald trump can talk abt democracy\n",
      "\n",
      "Rank 3 comment:\n",
      "eight continues can cme here spread but got chance spread sounds fair singapore ministers fucxxx fuxx off don talk please tell united states something make united states happy\n",
      "\n",
      "Rank 4 comment:\n",
      "mark zuckerbird like someone bought umbrella but they need united states buy one protect them from the rain lol\n",
      "\n",
      "Rank 5 comment:\n",
      "hope can visit batam soon beautiful adventure and looking forward\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# top comments containing joy emotion\n",
    "get_top_comments_by_emotions(df=df_emot, emotion='joy', n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1 comment:\n",
      "avijeet well tell that the doctor who presented his work and lab studies the covid gop conference the guy has been working covid since sars unbiaised has one the best credentials with regards this virus\n",
      "\n",
      "Rank 2 comment:\n",
      "angmo boss very happy more rrt thought won hope contract covid lorry soon\n",
      "\n",
      "Rank 3 comment:\n",
      "peter mish agree with you covid nineteen taught united states the importance having plan good all believe all can relate this\n",
      "\n",
      "Rank 4 comment:\n",
      "now the spike protein has been improved and made one hundred more lethal knowing that the virus was never isolated and thus lab manufactured welcome covid two zero upgraded version\n",
      "\n",
      "Rank 5 comment:\n",
      "singapore welcome omicron would like sincerely welcome you our country here you are exempted from any taxes and are free roam you get what mean hope you enjoy your stay\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# top comments containing joy emotion for topic 4\n",
    "get_corex_top_comments_by_emotions(topics_df=df_emot, topic=4, emotion='joy', n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1 comment:\n",
      "andylau google reporters without borders just deleted malaysia posts again one linked another explanation google contemptible and disgusting shitty paper\n",
      "\n",
      "Rank 2 comment:\n",
      "hate covid hate covid hate covid hate covid hate covid\n",
      "\n",
      "Rank 3 comment:\n",
      "demonthatgotlordkeith you are totally lame why don you just come out and say you are anti vaccine anti mask and anti lockdown during the pandemic your are being cowardly that what your talking about just say\n",
      "\n",
      "Rank 4 comment:\n",
      "don hate covid understand that the virus not responsible for making everyone suffer\n",
      "\n",
      "Rank 5 comment:\n",
      "cases yesterday and yet today simplify rules for travelers open doors for covid nineteen come stupid repeat the mistake stupid believing peoples action party stupidest\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# top comments containing anger emotion for topic 4\n",
    "get_corex_top_comments_by_emotions(topics_df=df_emot, topic=4, emotion='anger', n=5)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e4df196377e0d00ee5834a3e9d906ca8746586071202c506808b85f546d7b82d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
